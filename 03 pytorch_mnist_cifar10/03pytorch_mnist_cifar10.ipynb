{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:white; font-weight:bold; font-size:28px;\">mnist_pytorch</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Epoch: 001/10\n",
      "------------------------------------------------------------\n",
      "Train Loss: 0.2388 | Train Acc: 92.91%\n",
      "Val   Loss: 0.1364 | Val   Acc: 95.75%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 002/10\n",
      "------------------------------------------------------------\n",
      "Train Loss: 0.0950 | Train Acc: 97.11%\n",
      "Val   Loss: 0.0958 | Val   Acc: 97.04%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 003/10\n",
      "------------------------------------------------------------\n",
      "Train Loss: 0.0688 | Train Acc: 97.82%\n",
      "Val   Loss: 0.0797 | Val   Acc: 97.52%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 004/10\n",
      "------------------------------------------------------------\n",
      "Train Loss: 0.0526 | Train Acc: 98.30%\n",
      "Val   Loss: 0.0985 | Val   Acc: 96.93%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 005/10\n",
      "------------------------------------------------------------\n",
      "Train Loss: 0.0402 | Train Acc: 98.70%\n",
      "Val   Loss: 0.0986 | Val   Acc: 97.24%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 006/10\n",
      "------------------------------------------------------------\n",
      "Train Loss: 0.0359 | Train Acc: 98.87%\n",
      "Val   Loss: 0.0873 | Val   Acc: 97.50%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 007/10\n",
      "------------------------------------------------------------\n",
      "Train Loss: 0.0321 | Train Acc: 98.91%\n",
      "Val   Loss: 0.0735 | Val   Acc: 97.89%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 008/10\n",
      "------------------------------------------------------------\n",
      "Train Loss: 0.0266 | Train Acc: 99.14%\n",
      "Val   Loss: 0.0759 | Val   Acc: 98.01%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 009/10\n",
      "------------------------------------------------------------\n",
      "Train Loss: 0.0214 | Train Acc: 99.30%\n",
      "Val   Loss: 0.0890 | Val   Acc: 97.92%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 010/10\n",
      "------------------------------------------------------------\n",
      "Train Loss: 0.0211 | Train Acc: 99.27%\n",
      "Val   Loss: 0.0896 | Val   Acc: 97.88%\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 200)\n",
    "        self.fc2 = nn.Linear(200, 120)\n",
    "        self.fc3 = nn.Linear(120, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = Net().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', threshold=0.01, patience=5, factor=0.5)\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss = 0.0\n",
    "    train_acc = []\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc = np.append(train_acc, (torch.argmax(outputs.cpu(), dim=1) == labels.cpu()).numpy())\n",
    "    avg_train_loss = train_loss / len(trainloader)\n",
    "    avg_train_acc = np.mean(train_acc)\n",
    "    scheduler.step(avg_train_loss)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    val_acc = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc = np.append(val_acc, (torch.argmax(outputs.cpu(), dim=1) == labels.cpu()).numpy())\n",
    "    avg_val_loss = val_loss / len(valloader)\n",
    "    avg_val_acc = np.mean(val_acc)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Epoch: {epoch + 1:03d}/10\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc * 100:.2f}%\")\n",
    "    print(f\"Val   Loss: {avg_val_loss:.4f} | Val   Acc: {avg_val_acc * 100:.2f}%\")\n",
    "    print(\"=\" * 60, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring the Dataset Structure\n",
      "\n",
      "Train Images Shape: torch.Size([1, 1, 28, 28])\n",
      "Train Labels Length: 1\n",
      "Sample Train Labels: [1]\n",
      "\n",
      "Test Images Shape: torch.Size([1, 1, 28, 28])\n",
      "Test Labels Length: 1\n",
      "Sample Test Labels: [7]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# دانلود مجموعه داده MNIST و تبدیل به Tensor\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# بارگذاری داده‌ها در DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,  shuffle=False)\n",
    "\n",
    "# دریافت یک batch از داده‌ها\n",
    "train_images, train_labels = next(iter(train_loader))\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "# نمایش اطلاعات مجموعه داده\n",
    "print(\"Exploring the Dataset Structure\\n\")\n",
    "\n",
    "# اطلاعات داده‌های آموزشی\n",
    "print(\"Train Images Shape:\", train_images.shape)  # (64, 1, 28, 28)\n",
    "print(\"Train Labels Length:\", len(train_labels))  # 64\n",
    "print(\"Sample Train Labels:\", train_labels[:10].tolist())  # نمایش ۱۰ نمونه برچسب\n",
    "\n",
    "# اطلاعات داده‌های آزمایشی\n",
    "print(\"\\nTest Images Shape:\", test_images.shape)  # (64, 1, 28, 28)\n",
    "print(\"Test Labels Length:\", len(test_labels))  # 64\n",
    "print(\"Sample Test Labels:\", test_labels[:10].tolist())  # نمایش ۱۰ نمونه برچسب\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:white; font-weight:bold; font-size:28px;\">cifar10_pytorch</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Epoch: 001/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.8671 | Train Acc: 31.75%\n",
      "Val   Loss: 1.7177 | Val   Acc: 37.89%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 002/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.6808 | Train Acc: 39.35%\n",
      "Val   Loss: 1.6266 | Val   Acc: 41.78%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 003/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.5913 | Train Acc: 42.55%\n",
      "Val   Loss: 1.5469 | Val   Acc: 44.27%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 004/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.5262 | Train Acc: 45.41%\n",
      "Val   Loss: 1.5626 | Val   Acc: 44.57%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 005/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.4791 | Train Acc: 47.10%\n",
      "Val   Loss: 1.5121 | Val   Acc: 46.24%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 006/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.4460 | Train Acc: 48.12%\n",
      "Val   Loss: 1.4835 | Val   Acc: 47.35%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 007/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.4062 | Train Acc: 49.61%\n",
      "Val   Loss: 1.4810 | Val   Acc: 47.50%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 008/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.3782 | Train Acc: 50.40%\n",
      "Val   Loss: 1.4510 | Val   Acc: 48.48%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 009/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.3481 | Train Acc: 51.57%\n",
      "Val   Loss: 1.4504 | Val   Acc: 49.49%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 010/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.3251 | Train Acc: 52.33%\n",
      "Val   Loss: 1.4398 | Val   Acc: 49.86%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 011/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.2969 | Train Acc: 53.21%\n",
      "Val   Loss: 1.4388 | Val   Acc: 49.50%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 012/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.2686 | Train Acc: 54.21%\n",
      "Val   Loss: 1.4215 | Val   Acc: 49.55%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 013/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.2470 | Train Acc: 55.23%\n",
      "Val   Loss: 1.4112 | Val   Acc: 50.89%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 014/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.2283 | Train Acc: 55.85%\n",
      "Val   Loss: 1.4216 | Val   Acc: 50.32%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 015/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.2054 | Train Acc: 56.48%\n",
      "Val   Loss: 1.4101 | Val   Acc: 51.10%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 016/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.1806 | Train Acc: 57.47%\n",
      "Val   Loss: 1.4532 | Val   Acc: 50.27%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 017/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.1616 | Train Acc: 58.06%\n",
      "Val   Loss: 1.4537 | Val   Acc: 50.13%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 018/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.1454 | Train Acc: 58.86%\n",
      "Val   Loss: 1.4413 | Val   Acc: 50.12%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 019/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.1233 | Train Acc: 59.59%\n",
      "Val   Loss: 1.4530 | Val   Acc: 50.41%\n",
      "============================================================ \n",
      "\n",
      "============================================================\n",
      "Epoch: 020/20\n",
      "------------------------------------------------------------\n",
      "Train Loss: 1.1055 | Train Acc: 60.21%\n",
      "Val   Loss: 1.4582 | Val   Acc: 51.05%\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0, 0, 0), (1, 1, 1))\n",
    "])\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = Net().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', threshold=0.01, patience=5, factor=0.5)\n",
    "\n",
    "for epoch in range(20):\n",
    "    train_loss = 0.0\n",
    "    train_acc = []\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc = np.append(train_acc, (torch.argmax(outputs.cpu(), dim=1) == labels.cpu()).numpy())\n",
    "    avg_train_loss = train_loss / len(trainloader)\n",
    "    avg_train_acc = np.mean(train_acc)\n",
    "    scheduler.step(avg_train_loss)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    val_acc = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc = np.append(val_acc, (torch.argmax(outputs.cpu(), dim=1) == labels.cpu()).numpy())\n",
    "    avg_val_loss = val_loss / len(valloader)\n",
    "    avg_val_acc = np.mean(val_acc)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Epoch: {epoch + 1:03d}/20\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc * 100:.2f}%\")\n",
    "    print(f\"Val   Loss: {avg_val_loss:.4f} | Val   Acc: {avg_val_acc * 100:.2f}%\")\n",
    "    print(\"=\" * 60, \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
